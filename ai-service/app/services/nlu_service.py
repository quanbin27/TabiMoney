"""
Natural Language Understanding Service
NLU functionality for TabiMoney AI Service
"""

import asyncio
import logging
from typing import Dict, Any, List, Optional, Tuple
import re
from datetime import datetime, timedelta
import httpx
import json

"""NLU service using Gemini or local Ollama; OpenAI removed."""

from app.core.config import settings
import aiohttp
from app.models.nlu import NLURequest, NLUResponse, Entity, ChatRequest, ChatResponse
from app.core.database import get_db
from app.services.transaction_service import TransactionService

logger = logging.getLogger(__name__)


class NLUService:
    """Natural Language Understanding Service"""
    
    def __init__(self):
        self.client: Optional[object] = None
        self.ollama_client: Optional[httpx.AsyncClient] = None
        self.is_initialized = False
        self.transaction_service = TransactionService()
        
        # Common patterns for entity extraction
        self.amount_patterns = [
            r'(\d+(?:\.\d+)?)\s*(?:k|ngh√¨n|thousand)',
            r'(\d+(?:\.\d+)?)\s*(?:tr|tri·ªáu|million)',
            r'(\d+(?:\.\d+)?)\s*(?:t·ª∑|billion)',
            r'(\d+(?:\.\d+)?)\s*(?:ƒë|dong|vnd)',
            r'(\d+(?:\.\d+)?)'
        ]
        
        self.category_keywords = {
            'ƒÉn u·ªëng': ['ƒÉn', 'u·ªëng', 'c∆°m', 'ph·ªü', 'b√∫n', 'ch√°o', 'c√† ph√™', 'tr√†', 'n∆∞·ªõc', 'restaurant', 'food'],
            'giao th√¥ng': ['xe', 'taxi', 'bus', 'm√°y bay', 't√†u', 'xƒÉng', 'd·∫ßu', 'transport', 'travel'],
            'mua s·∫Øm': ['mua', 's·∫Øm', 'qu·∫ßn √°o', 'gi√†y', 't√∫i', 'shop', 'shopping', 'clothes'],
            'gi·∫£i tr√≠': ['phim', 'game', 'du l·ªãch', 'karaoke', 'bar', 'club', 'entertainment', 'movie'],
            'y t·∫ø': ['b·ªánh vi·ªán', 'kh√°m', 'thu·ªëc', 'b√°c sƒ©', 'health', 'medical', 'hospital'],
            'h·ªçc t·∫≠p': ['h·ªçc', 's√°ch', 'kh√≥a h·ªçc', 'education', 'study', 'book', 'course'],
            'ti·∫øt ki·ªám': ['ti·∫øt ki·ªám', 'ƒë·∫ßu t∆∞', 'savings', 'investment', 'save'],
            'kh√°c': ['kh√°c', 'other', 'misc']
        }
    
    async def initialize(self):
        """Initialize NLU service"""
        logger.info("Initializing NLU Service...")
        
        try:
            if settings.USE_GEMINI and settings.GEMINI_API_KEY:
                # Prefer Gemini if configured
                self.ollama_client = None
                self.client = None
                await self._test_gemini_connection()
                logger.info("NLU Service initialized with Gemini")
            else:
                # Force use Ollama when USE_OPENAI is False
                self.ollama_client = httpx.AsyncClient(timeout=30.0)
                await self._test_ollama_connection()
                logger.info("NLU Service initialized with Ollama (forced)")
            
            self.is_initialized = True
            
        except Exception as e:
            logger.error(f"Failed to initialize NLU Service: {e}")
            # Fallback to rule-based NLU
            self.is_initialized = True
            logger.info("NLU Service initialized with rule-based fallback")
    
    async def cleanup(self):
        """Cleanup NLU service"""
        logger.info("Cleaning up NLU Service...")
        self.client = None
        if self.ollama_client:
            await self.ollama_client.aclose()
        self.is_initialized = False
    
    def is_ready(self) -> bool:
        """Check if NLU service is ready"""
        return self.is_initialized
    
    # OpenAI support removed

    async def _test_gemini_connection(self):
        """Test Gemini API connection"""
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{settings.GEMINI_MODEL}:generateContent?key={settings.GEMINI_API_KEY}"
                payload = {"contents": [{"parts": [{"text": "ping"}]}]}
                async with session.post(url, json=payload) as resp:
                    if resp.status != 200:
                        raise Exception(f"Gemini returned status {resp.status}")
        except Exception as e:
            logger.error(f"Gemini API connection failed: {e}")
            raise
    
    async def _test_ollama_connection(self):
        """Test Ollama connection"""
        try:
            response = await self.ollama_client.post(
                f"{settings.OLLAMA_BASE_URL}/api/generate",
                json={
                    "model": settings.LLM_MODEL,
                    "prompt": "Hello",
                    "stream": False
                }
            )
            if response.status_code == 200:
                logger.info("Ollama connection test successful")
            else:
                raise Exception(f"Ollama returned status {response.status_code}")
        except Exception as e:
            logger.error(f"Ollama connection test failed: {e}")
            raise
    
    async def process_nlu(self, request: NLURequest) -> NLUResponse:
        """Process Natural Language Understanding request"""
        if not self.is_ready():
            raise RuntimeError("NLU Service not ready")
        
        try:
            # Try AI service first if available
            if settings.USE_GEMINI and settings.GEMINI_API_KEY:
                return await self._process_with_gemini(request)
            elif self.ollama_client:
                return await self._process_with_ollama(request)
            else:
                return await self._process_with_rules(request)
                
        except Exception as e:
            logger.error(f"Failed to process NLU: {e}")
            # Fallback to rule-based processing
            return await self._process_with_rules(request)
    
    # OpenAI processing removed
    
    async def _process_with_ollama(self, request: NLURequest) -> NLUResponse:
        """Process NLU using Ollama"""
        try:
            prompt = await self._build_prompt_with_categories(request.text, request.user_id, request.context)
            
            response = await self.ollama_client.post(
                f"{settings.OLLAMA_BASE_URL}/api/generate",
                json={
                    "model": settings.LLM_MODEL,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.3,
                        "max_tokens": 300
                    }
                }
            )
            
            if response.status_code != 200:
                raise Exception(f"Ollama returned status {response.status_code}")
            
            # Ollama returns JSON with { response: "..." }
            # Read as text first for resilience
            text_body = await response.aread()
            try:
                result = json.loads(text_body.decode("utf-8", errors="ignore"))
                content = result.get("response", "")
            except Exception:
                content = text_body.decode("utf-8", errors="ignore")

            # Try to parse structured JSON from model output
            try:
                parsed = self._parse_openai_response(self._extract_json_block(content), request.user_id, request.text)
                parsed = await self._normalize_entities_add_category_id(parsed, request.user_id)
                return parsed
            except Exception:
                logger.warning("Falling back to rule-based NLU due to parse failure")
                return await self._process_with_rules(request)
            
        except Exception as e:
            logger.error(f"Ollama NLU processing failed: {e}")
            raise

    async def _process_with_gemini(self, request: NLURequest) -> NLUResponse:
        """Process NLU using Google Gemini"""
        try:
            logger.info(f"Processing with Gemini: {request.text}")
            prompt = await self._build_prompt_with_categories(request.text, request.user_id, request.context)
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60)) as session:
                url = f"https://generativelanguage.googleapis.com/v1beta/models/{settings.GEMINI_MODEL}:generateContent?key={settings.GEMINI_API_KEY}"
                payload = {
                    "contents": [
                        {"parts": [
                            {"text": "B·∫°n l√† NLU, lu√¥n tr·∫£ v·ªÅ CH·ªà JSON ƒë√∫ng schema, kh√¥ng vƒÉn b·∫£n kh√°c."},
                            {"text": prompt}
                        ]}
                    ],
                    "generationConfig": {
                        "temperature": settings.GEMINI_TEMPERATURE,
                        "maxOutputTokens": 4000,  # Increase token limit
                        "response_mime_type": "application/json"
                    }
                }
                async with session.post(url, json=payload) as resp:
                    logger.info(f"Gemini response status: {resp.status}")
                    if resp.status != 200:
                        logger.error(f"Gemini returned status {resp.status}")
                        # fallback to Ollama
                        if self.ollama_client:
                            return await self._process_with_ollama(request)
                        raise Exception(f"Gemini returned status {resp.status}")
                    data = await resp.json()
                    logger.info(f"Gemini raw response: {json.dumps(data, indent=2)[:500]}...")
                    # Extract text
                    content = ""
                    try:
                        # Try different response formats
                        if "candidates" in data and len(data["candidates"]) > 0:
                            candidate = data["candidates"][0]
                            if "content" in candidate and "parts" in candidate["content"]:
                                content = candidate["content"]["parts"][0]["text"]
                            elif "text" in candidate:
                                content = candidate["text"]
                        elif "text" in data:
                            content = data["text"]
                        else:
                            content = json.dumps(data)
                        logger.info(f"Gemini response content: {content}")
                    except Exception as e:
                        logger.error(f"Failed to extract Gemini content: {e}")
                        content = json.dumps(data)
                    # Parse structured json
                    try:
                        parsed = self._parse_openai_response(self._extract_json_block(content), request.user_id, request.text)
                        parsed = await self._normalize_entities_add_category_id(parsed, request.user_id)
                        logger.info(f"Gemini parsing successful: intent={parsed.intent}")
                        return parsed
                    except Exception as e:
                        logger.warning(f"Falling back to Ollama due to parse failure (Gemini): {e}")
                        if self.ollama_client:
                            return await self._process_with_ollama(request)
                        return await self._process_with_rules(request)
        except Exception as e:
            logger.error(f"Gemini NLU processing failed: {e}")
            # fallback to Ollama
            if self.ollama_client:
                return await self._process_with_ollama(request)
            raise
    
    async def _build_prompt_with_categories(self, text: str, user_id: int, context: str) -> str:
        """Build prompt including allowed categories (id|name) and strict schema returning category_id."""
        # Query top used categories for this user (and include system categories)
        allowed: List[Dict[str, Any]] = []
        try:
            async with get_db() as db:
                rows = await db.execute(
                    (
                        "SELECT c.id, c.name, c.name_en, COALESCE(COUNT(t.id),0) as usage_count "
                        "FROM categories c "
                        "LEFT JOIN transactions t ON t.category_id = c.id AND t.user_id = %s "
                        "WHERE c.is_active = TRUE AND (c.user_id IS NULL OR c.user_id = %s) "
                        "GROUP BY c.id, c.name, c.name_en "
                        "ORDER BY usage_count DESC, c.sort_order ASC, c.id ASC "
                        "LIMIT 30"
                    ),
                    (user_id, user_id)
                )
                allowed = rows or []
        except Exception as e:
            logger.warning(f"Failed to fetch categories for prompt: {e}")
            allowed = []

        def _fmt_cat(cat: Dict[str, Any]) -> str:
            name = cat.get("name") or ""
            name_en = cat.get("name_en") or ""
            if name_en and name_en.lower() != name.lower():
                return f"{cat['id']}|{name} ({name_en})"
            return f"{cat['id']}|{name}"

        allowed_lines = "\n".join(f"- {_fmt_cat(c)}" for c in allowed)

        # AI Agent t·ª± ch·ªß ho√†n to√†n
        prompt = f"""B·∫°n l√† AI Agent qu·∫£n l√Ω t√†i ch√≠nh c√° nh√¢n. Ph√¢n t√≠ch c√¢u v√† quy·∫øt ƒë·ªãnh h√†nh ƒë·ªông:

Database c√≥ s·∫µn:
- Danh m·ª•c: {allowed_lines if allowed_lines else "9|Kh√°c"}
- B·∫°n c√≥ th·ªÉ: t·∫°o transaction, query balance, ph√¢n t√≠ch d·ªØ li·ªáu

Schema:
{{"intent":"add_transaction|query_balance|analyze_data|budget_management|goal_tracking|smart_recommendations|expense_forecasting|general","entities":[{{"type":"amount|category_id|date|description|budget_amount|goal_amount","value":"...","confidence":0.9,"start_pos":0,"end_pos":5}}],"confidence":0.9,"needs_confirmation":false,"response":"Ph·∫£n h·ªìi t·ª± nhi√™n","action":"m√¥ t·∫£ h√†nh ƒë·ªông s·∫Ω th·ª±c hi·ªán"}}

QUAN TR·ªåNG - Parse amount:
- Khi extract amount entity, PH·∫¢I chuy·ªÉn ƒë·ªïi v·ªÅ s·ªë VND ƒë·∫ßy ƒë·ªß:
  * "16 tri·ªáu" ho·∫∑c "16 tr" ‚Üí value: "16000000"
  * "400k" ho·∫∑c "400 ngh√¨n" ‚Üí value: "400000"
  * "2 t·ª∑" ‚Üí value: "2000000000"
  * "100000" ‚Üí value: "100000" (gi·ªØ nguy√™n)
- KH√îNG bao gi·ªù tr·∫£ v·ªÅ value l√† "16" n·∫øu trong c√¢u c√≥ "16 tri·ªáu"
- value ph·∫£i l√† s·ªë thu·∫ßn t√∫y (kh√¥ng c√≥ text, kh√¥ng c√≥ ƒë∆°n v·ªã)

Quy·∫øt ƒë·ªãnh:
- T·ª± ph√¢n t√≠ch intent t·ª´ context
- T·ª± ch·ªçn category ph√π h·ª£p nh·∫•t
- T·ª± quy·∫øt ƒë·ªãnh c√≥ c·∫ßn x√°c nh·∫≠n kh√¥ng
- T·ª± m√¥ t·∫£ action s·∫Ω l√†m
- T·ª± parse amount v·ªÅ VND ƒë·∫ßy ƒë·ªß

Input: "{text}"
Output:"""

        return prompt
    
    async def _process_with_rules(self, request: NLURequest) -> NLUResponse:
        """Process NLU using rule-based approach as fallback"""
        try:
            entities = self._extract_entities_rule_based(request.text)
            intent = self._determine_intent_rule_based(request.text, entities)
            response = self._generate_response_rule_based(intent, entities)
            suggested_action = self._get_suggested_action(intent)
            
            return NLUResponse(
                user_id=request.user_id,
                intent=intent,
                entities=entities,
                confidence=0.6,
                suggested_action=suggested_action,
                response=response,
                generated_at=datetime.now().isoformat() + "Z"
            )
        except Exception as e:
            logger.error(f"Rule-based NLU processing failed: {e}")
            # Return minimal fallback
            return NLUResponse(
                user_id=request.user_id,
                intent="general",
                entities=[],
                confidence=0.0,
                suggested_action="general_response",
                response="Xin l·ªói, t√¥i kh√¥ng hi·ªÉu y√™u c·∫ßu c·ªßa b·∫°n.",
                generated_at=datetime.now().isoformat() + "Z"
            )
    
    def _parse_openai_response(self, content: str, user_id: int, original_text: str = "") -> NLUResponse:
        """Parse OpenAI response"""
        try:
            import json
            data = json.loads(content)
            
            entities = []
            for entity_data in data.get('entities', []):
                value = entity_data.get('value')
                ent_type = entity_data.get('type')
                # AI model should already return normalized amount value (in VND)
                # Just ensure it's a valid number string
                if ent_type == 'amount' and isinstance(value, str):
                    # Try to parse as float to validate
                    try:
                        float(value)
                        # If it's a valid number, keep it as is (AI already normalized it)
                    except ValueError:
                        # If not a pure number, try to parse it (fallback for older AI responses)
                        num_match = re.search(r"\d+(?:[\.,]\d+)?", value)
                        if num_match:
                            num_text = num_match.group(0).replace(',', '.')
                            parsed_amount = self._parse_amount(num_text, value)
                            if parsed_amount > 0:
                                value = str(parsed_amount)
                entity = Entity(
                    type=ent_type,
                    value=value,
                    confidence=entity_data.get('confidence', 0.0),
                    start_pos=entity_data.get('start_pos', 0),
                    end_pos=entity_data.get('end_pos', 0)
                )
                entities.append(entity)
            
            return NLUResponse(
                user_id=user_id,
                intent=data.get('intent', 'general'),
                entities=entities,
                confidence=data.get('confidence', 0.0),
                suggested_action=data.get('suggested_action', 'general_response'),
                response=data.get('response', 'Xin l·ªói, t√¥i kh√¥ng hi·ªÉu y√™u c·∫ßu c·ªßa b·∫°n.'),
                needs_confirmation=data.get('needs_confirmation', False),
                generated_at=datetime.now().isoformat() + "Z"
            )
            
        except Exception as e:
            logger.error(f"Failed to parse OpenAI response: {e}")
            raise

    async def _normalize_entities_add_category_id(self, nlu: NLUResponse, user_id: int) -> NLUResponse:
        """If only a 'category' name is present, resolve and append 'category_id', then remove 'category'."""
        try:
            has_category_id = any(e.type == 'category_id' for e in nlu.entities)
            category_name_entity = next((e for e in nlu.entities if e.type == 'category'), None)
            
            # If already has category_id, remove any category entities
            if has_category_id:
                nlu.entities = [e for e in nlu.entities if e.type != 'category']
                logger.info(f"Removed category entities, kept category_id")
                return nlu
                
            if not category_name_entity or not isinstance(category_name_entity.value, str):
                return nlu
            # resolve via DB
            name_l = category_name_entity.value.strip().lower()
            async with get_db() as db:
                rows = await db.execute(
                    (
                        "SELECT c.id, c.name, COALESCE(c.name_en, '') as name_en FROM categories c "
                        "WHERE c.is_active = TRUE AND (c.user_id IS NULL OR c.user_id = %s)"
                    ),
                    (user_id,)
                )
            resolved_id: Optional[int] = None
            if rows:
                exact_vi = next((r for r in rows if r['name'].strip().lower() == name_l), None)
                if exact_vi:
                    resolved_id = int(exact_vi['id'])
                if resolved_id is None:
                    partial_vi = next((r for r in rows if name_l in r['name'].strip().lower()), None)
                    if partial_vi:
                        resolved_id = int(partial_vi['id'])
                if resolved_id is None:
                    exact_en = next((r for r in rows if r['name_en'] and r['name_en'].strip().lower() == name_l), None)
                    if exact_en:
                        resolved_id = int(exact_en['id'])
                if resolved_id is None:
                    partial_en = next((r for r in rows if r['name_en'] and name_l in r['name_en'].strip().lower()), None)
                    if partial_en:
                        resolved_id = int(partial_en['id'])
                if resolved_id is None:
                    other = next((r for r in rows if r['name'].strip().lower() == 'kh√°c'), None)
                    if other:
                        resolved_id = int(other['id'])
            if resolved_id is not None:
                # Remove the old category entity and add category_id
                nlu.entities = [e for e in nlu.entities if e.type != 'category']
                nlu.entities.append(
                    Entity(
                        type='category_id',
                        value=str(resolved_id),
                        confidence=category_name_entity.confidence or 0.7,
                        start_pos=category_name_entity.start_pos,
                        end_pos=category_name_entity.end_pos,
                    )
                )
        except Exception as e:
            logger.warning(f"normalize_entities_add_category_id failed: {e}")
        return nlu

    def _extract_json_block(self, content: str) -> str:
        """Extract JSON block from LLM output (handles code fences and extra text)."""
        if not content:
            raise ValueError("empty content")
        # Remove code fences
        content = content.strip()
        if content.startswith("```"):
            content = content.strip('`')
        # Find first {...} JSON object
        import re
        match = re.search(r"\{[\s\S]*\}", content)
        if match:
            return match.group(0)
        # If not found, assume content itself is JSON
        return content
    
    def _extract_entities_rule_based(self, text: str) -> List[Entity]:
        """Extract entities using rule-based approach"""
        entities = []
        
        # Extract amounts
        for pattern in self.amount_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                amount_text = match.group(1)
                amount_value = self._parse_amount(amount_text, text[match.start():match.end()])
                
                entity = Entity(
                    type="amount",
                    value=str(amount_value),
                    confidence=0.8,
                    start_pos=match.start(),
                    end_pos=match.end()
                )
                entities.append(entity)
        
        # Extract categories
        for category, keywords in self.category_keywords.items():
            for keyword in keywords:
                if keyword in text:
                    start_pos = text.find(keyword)
                    # Map category name to ID
                    category_id = self._get_category_id(category)
                    entity = Entity(
                        type="category_id",
                        value=str(category_id),
                        confidence=0.7,
                        start_pos=start_pos,
                        end_pos=start_pos + len(keyword)
                    )
                    entities.append(entity)
                    break
        
        # Extract dates
        date_patterns = [
            r'h√¥m nay|today',
            r'h√¥m qua|yesterday',
            r'ng√†y mai|tomorrow',
            r'(\d{1,2})[\/\-](\d{1,2})[\/\-](\d{4})',  # DD/MM/YYYY
            r'(\d{1,2})[\/\-](\d{1,2})'  # DD/MM
        ]
        
        for pattern in date_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                date_value = self._parse_date(match.group(0))
                entity = Entity(
                    type="date",
                    value=date_value,
                    confidence=0.6,
                    start_pos=match.start(),
                    end_pos=match.end()
                )
                entities.append(entity)
        
        return entities
    
    def _get_category_id(self, category_name: str) -> int:
        """Map category name to ID"""
        category_mapping = {
            "ƒÇn u·ªëng": 1,
            "Giao th√¥ng": 2,
            "Mua s·∫Øm": 3,
            "Gi·∫£i tr√≠": 4,
            "S·ª©c kh·ªèe": 5,
            "H·ªçc t·∫≠p": 6,
            "Du l·ªãch": 7,
            "Thu nh·∫≠p": 8,
            "Kh√°c": 9
        }
        return category_mapping.get(category_name, 9)  # Default to "Kh√°c"
    
    def _determine_intent_rule_based(self, text: str, entities: List[Entity]) -> str:
        """Determine intent using rule-based approach"""
        # Check for query keywords first (more specific)
        query_keywords = ['bao nhi√™u', 't·ªïng', 't·ªïng c·ªông', 'chi ti√™u', 'thu nh·∫≠p', 's·ªë d∆∞', 'mu·ªën bi·∫øt', 'ki·ªÉm tra']
        if any(keyword in text for keyword in query_keywords):
            return "query_balance"
        
        # Check for goals keywords
        goal_keywords = ['m·ª•c ti√™u', 'goal', 'ti·∫øt ki·ªám', 'ƒë·∫ßu t∆∞', 'mua s·∫Øm', 'tr·∫£ n·ª£']
        if any(keyword in text for keyword in goal_keywords):
            if 't·∫°o' in text or ('th√™m' in text and 'm·ªõi' in text):
                return "create_goal"
            elif 'xem' in text or 'danh s√°ch' in text or 'list' in text:
                return "list_goals"
            elif 'c·∫≠p nh·∫≠t' in text or 'ƒë√≥ng g√≥p' in text or ('th√™m' in text and 'ti·ªÅn' in text) or ('ti·∫øt ki·ªám' in text and 'th√™m' in text):
                return "update_goal"
            else:
                return "list_goals"  # Default to list if unclear
        
        # Check for budget keywords
        budget_keywords = ['ng√¢n s√°ch', 'budget', 'h·∫°n m·ª©c', 'chi ti√™u']
        if any(keyword in text for keyword in budget_keywords):
            if 't·∫°o' in text or ('th√™m' in text and 'm·ªõi' in text):
                return "create_budget"
            elif 'xem' in text or 'danh s√°ch' in text or 'list' in text or 'ki·ªÉm tra' in text:
                return "list_budgets"
            elif 'c·∫≠p nh·∫≠t' in text or 'tr·∫°ng th√°i' in text or 't√¨nh h√¨nh' in text:
                return "update_budget"
            else:
                return "list_budgets"  # Default to list if unclear
        
        # Check for transaction-related keywords
        transaction_keywords = ['mua', 'mua', 'chi', 'ti√™u', 'ƒÉn', 'u·ªëng', 'ƒëi', 'mua s·∫Øm']
        if any(keyword in text for keyword in transaction_keywords):
            return "add_transaction"
        
        # Check for question keywords
        question_keywords = ['t·∫°i sao', 'nh∆∞ th·∫ø n√†o', 'l√†m sao', 'c√≥ th·ªÉ', 'c√≥ n√™n']
        if any(keyword in text for keyword in question_keywords):
            return "ask_question"
        
        # Default intent
        return "general"
    
    def _generate_response_rule_based(self, intent: str, entities: List[Entity]) -> str:
        """Generate response using rule-based approach"""
        if intent == "add_transaction":
            amount_entity = next((e for e in entities if e.type == "amount"), None)
            category_entity = next((e for e in entities if e.type == "category"), None)
            
            if amount_entity and category_entity:
                return f"T√¥i s·∫Ω gi√∫p b·∫°n th√™m giao d·ªãch {amount_entity.value} VND cho danh m·ª•c {category_entity.value}."
            elif amount_entity:
                return f"T√¥i s·∫Ω gi√∫p b·∫°n th√™m giao d·ªãch {amount_entity.value} VND."
            else:
                return "T√¥i s·∫Ω gi√∫p b·∫°n th√™m giao d·ªãch m·ªõi."
        
        elif intent == "query_balance":
            return "T√¥i s·∫Ω ki·ªÉm tra s·ªë d∆∞ v√† chi ti√™u c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ xem chi ti·∫øt trong trang Analytics ho·∫∑c Dashboard."
        
        elif intent == "ask_question":
            return "T√¥i s·∫Ω c·ªë g·∫Øng tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ t√†i ch√≠nh."
        
        else:
            return "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n qu·∫£n l√Ω t√†i ch√≠nh c√° nh√¢n."
    
    def _get_suggested_action(self, intent: str) -> str:
        """Get suggested action based on intent"""
        action_map = {
            "add_transaction": "create_transaction",
            "query_balance": "get_balance",
            "ask_question": "answer_question",
            "general": "general_response"
        }
        return action_map.get(intent, "general_response")
    
    def _parse_amount(self, amount_text: str, full_match: str) -> float:
        """Parse amount from text"""
        try:
            amount = float(amount_text)
            
            # Handle Vietnamese number suffixes
            if 'k' in full_match.lower() or 'ngh√¨n' in full_match.lower():
                amount *= 1000
            elif 'tri·ªáu' in full_match.lower() or 'tr' in full_match.lower():
                amount *= 1000000
            elif 't·ª∑' in full_match.lower():
                amount *= 1000000000
            
            return amount
        except ValueError:
            return 0.0
    
    def _parse_date(self, date_text: str) -> str:
        """Parse date from text"""
        today = datetime.now()
        
        if 'h√¥m nay' in date_text.lower() or 'today' in date_text.lower():
            return today.strftime('%Y-%m-%d')
        elif 'h√¥m qua' in date_text.lower() or 'yesterday' in date_text.lower():
            yesterday = today - timedelta(days=1)
            return yesterday.strftime('%Y-%m-%d')
        elif 'ng√†y mai' in date_text.lower() or 'tomorrow' in date_text.lower():
            tomorrow = today + timedelta(days=1)
            return tomorrow.strftime('%Y-%m-%d')
        else:
            # Try to parse DD/MM/YYYY or DD/MM
            import re
            match = re.search(r'(\d{1,2})[\/\-](\d{1,2})(?:[\/\-](\d{4}))?', date_text)
            if match:
                day, month, year = match.groups()
                year = year or today.year
                return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
        
        return today.strftime('%Y-%m-%d')
    
    async def process_chat(self, request: ChatRequest) -> ChatResponse:
        """Process chat message and return AI response"""
        if not self.is_ready():
            raise RuntimeError("NLU Service not ready")
        
        try:
            # Convert chat request to NLU request
            nlu_request = NLURequest(
                text=request.message,
                user_id=request.user_id,
                context="chat"
            )
            
            # Process with NLU
            nlu_response = await self.process_nlu(nlu_request)
            
            # AI t·ª± quy·∫øt ƒë·ªãnh action d·ª±a tr√™n intent
            if nlu_response.intent == "add_transaction" and not nlu_response.needs_confirmation:
                await self._handle_add_transaction(request.user_id, nlu_response)
            elif nlu_response.intent == "query_balance":
                await self._handle_query_balance(request.user_id, nlu_response)
            elif nlu_response.intent == "analyze_data":
                await self._handle_analyze_data(request.user_id, nlu_response)
            elif nlu_response.intent == "budget_management":
                await self._handle_budget_management(request.user_id, nlu_response)
            elif nlu_response.intent == "goal_tracking":
                await self._handle_goal_tracking(request.user_id, nlu_response)
            elif nlu_response.intent == "smart_recommendations":
                await self._handle_smart_recommendations(request.user_id, nlu_response)
            elif nlu_response.intent == "expense_forecasting":
                await self._handle_expense_forecasting(request.user_id, nlu_response)
            
            # Generate suggestions based on intent
            suggestions = self._generate_chat_suggestions(nlu_response.intent)
            
            return ChatResponse(
                user_id=request.user_id,
                message=request.message,
                response=nlu_response.response,
                intent=nlu_response.intent,
                entities=nlu_response.entities,
                suggestions=suggestions,
                generated_at=datetime.now().isoformat() + "Z"
            )
            
        except Exception as e:
            logger.error(f"Failed to process chat: {e}")
            # Return fallback response
            return ChatResponse(
                user_id=request.user_id,
                message=request.message,
                response="Xin l·ªói, t√¥i kh√¥ng th·ªÉ x·ª≠ l√Ω tin nh·∫Øn c·ªßa b·∫°n l√∫c n√†y. Vui l√≤ng th·ª≠ l·∫°i sau.",
                intent="error",
                entities=[],
                suggestions=["Th·ª≠ h·ªèi v·ªÅ chi ti√™u", "Ki·ªÉm tra s·ªë d∆∞", "Th√™m giao d·ªãch m·ªõi"],
                generated_at=datetime.now().isoformat() + "Z"
            )
    
    async def _handle_add_transaction(self, user_id: int, nlu_response: NLUResponse):
        """Handle adding transaction directly to database"""
        try:
            # Extract entities
            amount = None
            category_id = None
            
            for entity in nlu_response.entities:
                if entity.type == "amount":
                    amount = float(entity.value)
                elif entity.type == "category_id":
                    category_id = int(entity.value)
            
            if amount and category_id:
                # Determine transaction type based on category
                transaction_type = "expense"
                if category_id == 8:  # Thu nh·∫≠p category
                    transaction_type = "income"
                
                # Create transaction
                result = await self.transaction_service.create_transaction(
                    user_id=user_id,
                    category_id=category_id,
                    amount=amount,
                    description=nlu_response.response,  # Use AI response as description
                    transaction_type=transaction_type
                )
                
                if result["success"]:
                    # Update the response with success message
                    nlu_response.response = result["message"]
                    logger.info(f"Successfully created transaction for user {user_id}")
                else:
                    # Update with error message
                    nlu_response.response = result["message"]
                    logger.error(f"Failed to create transaction: {result.get('error')}")
            else:
                logger.warning(f"Missing required entities for transaction: amount={amount}, category_id={category_id}")
                
        except Exception as e:
            logger.error(f"Error handling add transaction: {e}")
            nlu_response.response = "C√≥ l·ªói x·∫£y ra khi th√™m giao d·ªãch."
    
    async def _handle_query_balance(self, user_id: int, nlu_response: NLUResponse):
        """Handle balance query directly"""
        try:
            result = await self.transaction_service.get_user_balance(user_id)
            if result["success"]:
                nlu_response.response = result["message"]
                logger.info(f"Successfully retrieved balance for user {user_id}")
            else:
                nlu_response.response = result["message"]
                logger.error(f"Failed to get balance: {result.get('error')}")
        except Exception as e:
            logger.error(f"Error handling balance query: {e}")
            nlu_response.response = "C√≥ l·ªói x·∫£y ra khi l·∫•y th√¥ng tin s·ªë d∆∞."
    
    async def _handle_analyze_data(self, user_id: int, nlu_response: NLUResponse):
        """AI t·ª± ph√¢n t√≠ch d·ªØ li·ªáu theo y√™u c·∫ßu"""
        try:
            # AI c√≥ th·ªÉ t·ª± quy·∫øt ƒë·ªãnh ph√¢n t√≠ch g√¨ d·ª±a tr√™n context
            # V√≠ d·ª•: spending patterns, category analysis, trends, etc.
            
            # L·∫•y d·ªØ li·ªáu giao d·ªãch g·∫ßn ƒë√¢y
            async with get_db() as db:
                # L·∫•y transactions 30 ng√†y g·∫ßn nh·∫•t
                transactions_query = """
                SELECT t.*, c.name as category_name 
                FROM transactions t 
                JOIN categories c ON t.category_id = c.id 
                WHERE t.user_id = %s 
                AND t.transaction_date >= DATE_SUB(CURDATE(), INTERVAL 30 DAY)
                ORDER BY t.transaction_date DESC
                LIMIT 50
                """
                
                transactions = await db.execute(transactions_query, (user_id,))
                
                if transactions:
                    # AI t·ª± ph√¢n t√≠ch v√† ƒë∆∞a ra insights
                    total_expense = sum(t['amount'] for t in transactions if t['transaction_type'] == 'expense')
                    total_income = sum(t['amount'] for t in transactions if t['transaction_type'] == 'income')
                    
                    # Ph√¢n t√≠ch theo category
                    category_spending = {}
                    for t in transactions:
                        if t['transaction_type'] == 'expense':
                            cat = t['category_name']
                            category_spending[cat] = category_spending.get(cat, 0) + t['amount']
                    
                    # T·∫°o response t·ª± nhi√™n
                    insights = []
                    if total_expense > 0:
                        insights.append(f"T·ªïng chi ti√™u 30 ng√†y: {total_expense:,.0f} VND")
                    if total_income > 0:
                        insights.append(f"T·ªïng thu nh·∫≠p 30 ng√†y: {total_income:,.0f} VND")
                    
                    if category_spending:
                        top_category = max(category_spending.items(), key=lambda x: x[1])
                        insights.append(f"Chi nhi·ªÅu nh·∫•t: {top_category[0]} ({top_category[1]:,.0f} VND)")
                    
                    nlu_response.response = "Ph√¢n t√≠ch 30 ng√†y g·∫ßn nh·∫•t:\n" + "\n".join(insights)
                else:
                    nlu_response.response = "Ch∆∞a c√≥ d·ªØ li·ªáu giao d·ªãch ƒë·ªÉ ph√¢n t√≠ch."
                    
        except Exception as e:
            logger.error(f"Error handling data analysis: {e}")
            nlu_response.response = "C√≥ l·ªói x·∫£y ra khi ph√¢n t√≠ch d·ªØ li·ªáu."
    
    async def _handle_budget_management(self, user_id: int, nlu_response: NLUResponse):
        """AI qu·∫£n l√Ω ng√¢n s√°ch th√¥ng minh"""
        try:
            async with get_db() as db:
                # L·∫•y ng√¢n s√°ch hi·ªán t·∫°i
                budget_query = """
                SELECT b.*, c.name as category_name 
                FROM budgets b 
                JOIN categories c ON b.category_id = c.id 
                WHERE b.user_id = %s AND b.is_active = true
                """
                budgets = await db.execute(budget_query, (user_id,))
                
                # L·∫•y chi ti√™u th√°ng n√†y
                expense_query = """
                SELECT c.name as category_name, SUM(t.amount) as total_spent
                FROM transactions t 
                JOIN categories c ON t.category_id = c.id 
                WHERE t.user_id = %s AND t.transaction_type = 'expense' 
                AND MONTH(t.transaction_date) = MONTH(CURDATE()) 
                AND YEAR(t.transaction_date) = YEAR(CURDATE())
                GROUP BY c.id, c.name
                """
                expenses = await db.execute(expense_query, (user_id,))
                
                if budgets:
                    insights = []
                    expense_dict = {e['category_name']: e['total_spent'] for e in expenses}
                    
                    for budget in budgets:
                        spent = expense_dict.get(budget['category_name'], 0)
                        remaining = budget['amount'] - spent
                        percentage = (spent / budget['amount']) * 100 if budget['amount'] > 0 else 0
                        
                        if percentage > 90:
                            insights.append(f"‚ö†Ô∏è {budget['category_name']}: {percentage:.0f}% ng√¢n s√°ch ({spent:,.0f}/{budget['amount']:,.0f} VND)")
                        elif percentage > 70:
                            insights.append(f"üü° {budget['category_name']}: {percentage:.0f}% ng√¢n s√°ch ({spent:,.0f}/{budget['amount']:,.0f} VND)")
                        else:
                            insights.append(f"‚úÖ {budget['category_name']}: {percentage:.0f}% ng√¢n s√°ch ({spent:,.0f}/{budget['amount']:,.0f} VND)")
                    
                    nlu_response.response = "üìä T√¨nh h√¨nh ng√¢n s√°ch th√°ng n√†y:\n" + "\n".join(insights)
                else:
                    nlu_response.response = "B·∫°n ch∆∞a c√≥ ng√¢n s√°ch n√†o. H√£y t·∫°o ng√¢n s√°ch ƒë·ªÉ qu·∫£n l√Ω chi ti√™u t·ªët h∆°n!"
                    
        except Exception as e:
            logger.error(f"Error handling budget management: {e}")
            nlu_response.response = "C√≥ l·ªói x·∫£y ra khi ki·ªÉm tra ng√¢n s√°ch."
    
    async def _handle_goal_tracking(self, user_id: int, nlu_response: NLUResponse):
        """AI theo d√µi m·ª•c ti√™u t√†i ch√≠nh"""
        try:
            async with get_db() as db:
                # L·∫•y goals hi·ªán t·∫°i
                goals_query = """
                SELECT * FROM financial_goals 
                WHERE user_id = %s AND is_achieved = false
                ORDER BY target_date ASC
                """
                goals = await db.execute(goals_query, (user_id,))
                
                if goals:
                    insights = []
                    for goal in goals:
                        # T√≠nh progress
                        progress_query = """
                        SELECT SUM(amount) as saved_amount
                        FROM transactions 
                        WHERE user_id = %s AND category_id = 8 AND transaction_type = 'income'
                        AND transaction_date >= %s
                        """
                        progress = await db.execute(progress_query, (user_id, goal['created_at']))
                        saved = progress[0]['saved_amount'] if progress and progress[0]['saved_amount'] else 0
                        
                        progress_percentage = (saved / goal['target_amount']) * 100 if goal['target_amount'] > 0 else 0
                        remaining = goal['target_amount'] - saved
                        
                        insights.append(f"üéØ {goal['title']}: {progress_percentage:.0f}% ({saved:,.0f}/{goal['target_amount']:,.0f} VND)")
                        if remaining > 0:
                            insights.append(f"   C√≤n l·∫°i: {remaining:,.0f} VND")
                    
                    nlu_response.response = "üéØ Ti·∫øn ƒë·ªô m·ª•c ti√™u:\n" + "\n".join(insights)
                else:
                    nlu_response.response = "B·∫°n ch∆∞a c√≥ m·ª•c ti√™u t√†i ch√≠nh n√†o. H√£y t·∫°o m·ª•c ti√™u ƒë·ªÉ c√≥ ƒë·ªông l·ª±c ti·∫øt ki·ªám!"
                    
        except Exception as e:
            logger.error(f"Error handling goal tracking: {e}")
            nlu_response.response = "C√≥ l·ªói x·∫£y ra khi ki·ªÉm tra m·ª•c ti√™u."
    
    async def _handle_smart_recommendations(self, user_id: int, nlu_response: NLUResponse):
        """AI ƒë∆∞a ra g·ª£i √Ω th√¥ng minh"""
        try:
            async with get_db() as db:
                # Ph√¢n t√≠ch chi ti√™u 3 th√°ng g·∫ßn nh·∫•t
                analysis_query = """
                SELECT c.name as category_name, 
                       SUM(t.amount) as total_spent,
                       COUNT(*) as transaction_count,
                       AVG(t.amount) as avg_amount
                FROM transactions t 
                JOIN categories c ON t.category_id = c.id 
                WHERE t.user_id = %s AND t.transaction_type = 'expense' 
                AND t.transaction_date >= DATE_SUB(CURDATE(), INTERVAL 3 MONTH)
                GROUP BY c.id, c.name
                ORDER BY total_spent DESC
                """
                analysis = await db.execute(analysis_query, (user_id,))
                
                if analysis:
                    recommendations = []
                    
                    # T√¨m category chi nhi·ªÅu nh·∫•t
                    top_category = analysis[0]
                    recommendations.append(f"üí° B·∫°n chi nhi·ªÅu nh·∫•t cho {top_category['category_name']} ({top_category['total_spent']:,.0f} VND)")
                    
                    # G·ª£i √Ω ti·∫øt ki·ªám
                    if top_category['category_name'] == 'ƒÇn u·ªëng':
                        recommendations.append("üçΩÔ∏è G·ª£i √Ω: N·∫•u ƒÉn ·ªü nh√† nhi·ªÅu h∆°n, h·∫°n ch·∫ø giao ƒë·ªì ƒÉn")
                    elif top_category['category_name'] == 'Giao th√¥ng':
                        recommendations.append("üöó G·ª£i √Ω: S·ª≠ d·ª•ng ph∆∞∆°ng ti·ªán c√¥ng c·ªông, ƒëi chung xe")
                    elif top_category['category_name'] == 'Mua s·∫Øm':
                        recommendations.append("üõçÔ∏è G·ª£i √Ω: Mua s·∫Øm c√≥ k·∫ø ho·∫°ch, tr√°nh mua s·∫Øm b·ªëc ƒë·ªìng")
                    
                    # Ph√¢n t√≠ch xu h∆∞·ªõng
                    if len(analysis) > 1:
                        second_category = analysis[1]
                        recommendations.append(f"üìà Xu h∆∞·ªõng: {second_category['category_name']} c≈©ng chi kh√° nhi·ªÅu ({second_category['total_spent']:,.0f} VND)")
                    
                    nlu_response.response = "ü§ñ G·ª£i √Ω th√¥ng minh:\n" + "\n".join(recommendations)
                else:
                    nlu_response.response = "Ch∆∞a c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ƒë∆∞a ra g·ª£i √Ω. H√£y th√™m nhi·ªÅu giao d·ªãch h∆°n!"
                    
        except Exception as e:
            logger.error(f"Error handling smart recommendations: {e}")
            nlu_response.response = "C√≥ l·ªói x·∫£y ra khi t·∫°o g·ª£i √Ω."
    
    async def _handle_expense_forecasting(self, user_id: int, nlu_response: NLUResponse):
        """AI d·ª± ƒëo√°n chi ti√™u t∆∞∆°ng lai"""
        try:
            async with get_db() as db:
                # Ph√¢n t√≠ch chi ti√™u 6 th√°ng g·∫ßn nh·∫•t
                forecast_query = """
                SELECT MONTH(transaction_date) as month, 
                       YEAR(transaction_date) as year,
                       SUM(amount) as monthly_expense
                FROM transactions 
                WHERE user_id = %s AND transaction_type = 'expense' 
                AND transaction_date >= DATE_SUB(CURDATE(), INTERVAL 6 MONTH)
                GROUP BY YEAR(transaction_date), MONTH(transaction_date)
                ORDER BY YEAR(transaction_date) DESC, MONTH(transaction_date) DESC
                """
                expenses = await db.execute(forecast_query, (user_id,))
                
                if len(expenses) >= 3:
                    # T√≠nh trung b√¨nh chi ti√™u
                    avg_expense = sum(e['monthly_expense'] for e in expenses) / len(expenses)
                    
                    # D·ª± ƒëo√°n th√°ng t·ªõi
                    next_month_forecast = avg_expense * 1.1  # TƒÉng 10% ƒë·ªÉ an to√†n
                    
                    # Ph√¢n t√≠ch xu h∆∞·ªõng
                    recent_avg = sum(e['monthly_expense'] for e in expenses[:3]) / 3
                    older_avg = sum(e['monthly_expense'] for e in expenses[3:]) / len(expenses[3:]) if len(expenses) > 3 else recent_avg
                    
                    trend = "tƒÉng" if recent_avg > older_avg else "gi·∫£m" if recent_avg < older_avg else "·ªïn ƒë·ªãnh"
                    
                    insights = [
                        f"üìä D·ª± ƒëo√°n chi ti√™u th√°ng t·ªõi: {next_month_forecast:,.0f} VND",
                        f"üìà Xu h∆∞·ªõng: {trend} ({recent_avg:,.0f} vs {older_avg:,.0f} VND)",
                        f"üí∞ Trung b√¨nh 6 th√°ng: {avg_expense:,.0f} VND"
                    ]
                    
                    nlu_response.response = "üîÆ D·ª± ƒëo√°n t√†i ch√≠nh:\n" + "\n".join(insights)
                else:
                    nlu_response.response = "C·∫ßn √≠t nh·∫•t 3 th√°ng d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n. H√£y s·ª≠ d·ª•ng app th∆∞·ªùng xuy√™n h∆°n!"
                    
        except Exception as e:
            logger.error(f"Error handling expense forecasting: {e}")
            nlu_response.response = "C√≥ l·ªói x·∫£y ra khi d·ª± ƒëo√°n chi ti√™u."
    
    def _generate_chat_suggestions(self, intent: str) -> List[str]:
        """AI t·ª± t·∫°o suggestions d·ª±a tr√™n context"""
        # AI c√≥ th·ªÉ t·ª± quy·∫øt ƒë·ªãnh suggestions ph√π h·ª£p
        all_suggestions = [
            "Th√™m giao d·ªãch m·ªõi",
            "Xem s·ªë d∆∞ th√°ng n√†y", 
            "Ph√¢n t√≠ch chi ti√™u",
            "Xem xu h∆∞·ªõng t√†i ch√≠nh",
            "G·ª£i √Ω ti·∫øt ki·ªám",
            "B√°o c√°o chi ti·∫øt"
        ]
        
        # T√πy theo intent, AI c√≥ th·ªÉ ch·ªçn suggestions ph√π h·ª£p
        if intent == "add_transaction":
            return ["Th√™m giao d·ªãch kh√°c", "Xem s·ªë d∆∞", "Ph√¢n t√≠ch chi ti√™u"]
        elif intent == "query_balance":
            return ["Th√™m giao d·ªãch", "Ph√¢n t√≠ch xu h∆∞·ªõng", "G·ª£i √Ω ti·∫øt ki·ªám"]
        elif intent == "analyze_data":
            return ["Xem chi ti·∫øt", "Th√™m giao d·ªãch", "B√°o c√°o ƒë·∫ßy ƒë·ªß"]
        elif intent == "budget_management":
            return ["T·∫°o ng√¢n s√°ch m·ªõi", "Xem chi ti·∫øt ng√¢n s√°ch", "ƒêi·ªÅu ch·ªânh ng√¢n s√°ch"]
        elif intent == "goal_tracking":
            return ["T·∫°o m·ª•c ti√™u m·ªõi", "C·∫≠p nh·∫≠t ti·∫øn ƒë·ªô", "Xem l·ªãch s·ª≠ m·ª•c ti√™u"]
        elif intent == "smart_recommendations":
            return ["G·ª£i √Ω ti·∫øt ki·ªám", "Ph√¢n t√≠ch chi ti√™u", "T·ªëi ∆∞u ng√¢n s√°ch"]
        elif intent == "expense_forecasting":
            return ["D·ª± ƒëo√°n d√†i h·∫°n", "Ph√¢n t√≠ch xu h∆∞·ªõng", "L·∫≠p k·∫ø ho·∫°ch t√†i ch√≠nh"]
        else:
            return all_suggestions[:3]  # AI t·ª± ch·ªçn 3 suggestions ph√π h·ª£p
